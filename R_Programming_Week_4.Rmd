---
title: "R Programming Week 4"
author: "Rudy Rupp"
date: "13/10/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# R Programming Week 4: Simulation and Profiling  
Simulating data in R can be useful for simulation studies. The profiler tool lets you collect detailed information about how your functions are running, to identify bottlenecks that need to be addressed. This week also covers the use of the STR function. 

**Learning Objectives**
 * Call the 'str' function on an object.  
 * describe the difference beween the 'by.self' and 'by.total' output produced by the R profiler.  
 * Simulate a random normal variable with an arbitrary mean and standard deviation.  
 * Simulate data form a normal linear model.  
 
## The 'str' Function  
It compactly displays the internal structure of a object. It's a simple diagnostic function, similar to 'summary'. It's particularly well suited to displaying the contents of nested lists, and tries to give only one line per basic object.
```{r}
str(str)
str(lm) ## gives arguments of a function

x <- rnorm(100, 2, 4)
summary(x)
str(x)  ## gives different information

f <- gl(40, 10)
str(f)
summary(f)  ## summary is not as useful in this case.

library(datasets)
str(airquality)  ## output for a data frame

m <- matrix(rnorm(100), 10, 10)
str(m)  ## results for a matrix, dimensions and sample of first column

s <- split(airquality, airquality$Month)
 ## this is a list with 5 data frames, each one a piece of the 
 ## original, separated by month.
str(s)  ## gives some detail for each element
```  

## Simulation - Generating Random Numbers  
```{r, echo = FALSE}
str(list(dnorm = dnorm, pnorm = pnorm, qnorm = qnorm, rnorm = rnorm))
```  

 * `rnorm`: random normal variates, with given mean and standard deviation.   


Mean and sd must be provided, otherwise default values are used.  

 * `dnorm` calculates the density. I.e.: for a value of `x`, the function gives the frequency (vertical axis) of the distribution. Equivalent of applying the normal distribution function  
 $$\frac{1}{\sigma\sqrt{2\pi}} * e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$ 
 
     * The Log can be calculated instead, but is FALSE by default. 
     * It's useful to think of `x` in `dnorm` as the z-score, for the standard normal distribution. 
  * `pnorm` returns the area under the curve, from $-\infty$ to `q`. `q` is a z-score. (I.e. the probability that any given value of the population falls between $-\infty$ and `q`.)  
  * `qnorm` is the opposite of `pnorm`. Given a probability `p`, it returns the z-score for that probability.  
    * `pnorm` and `qnorm` also can evaluate the Log, and also have an option for the lower tail. This is the left side of the distribution. Setting it to FALSE will determine the upper tail instead. 
 * The same 4 functions exist for different distributions, too. E.g. pois for poisson and unif for uniform, gamma for gama, etc.
 
**When using random number generators, you must set a seed first, for the values to be reproducible**
```{r}
set.seed(1)
rnorm(5)
rnorm(5)  ## different from original, seed not set.
set.seed(1)
rnorm(5)  ## equal to original, seed has been set.
```  

## Simulation - Simulating a Linear Model
 Suppose we want to simulate the model
 $$y = \beta_{0} + \beta_{l} x + \varepsilon$$
 where $\varepsilon \sim N(0, 2^2)$.  Assume $x \sim N(0, 1^2)$, $\beta_{0} = 0.5$ and $\beta_{l} = 2$.
```{r}
set.seed(20)
x <- rnorm(100)
e <- rnorm(100, 0, 2)
y <- 0.5 + 2 * x + e
summary(y)
plot(x, y)
```  

Suppose we want to simulate from a Poisson model where
$$Y \sim Poisson(\mu)$$
$$log(\mu) = \beta_0 + \beta_l x$$
and $\beta_0 = 0.5$ and $\beta_l = 0.3$. We need to use `rpois` function for this 
```{r}
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3 * x
y <- rpois(100, exp(log.mu))
summary(y)
plot(x, y)
```  

## Simulation - Random Sampling  
The `sample` function allows us to get random samples from a vector of numbers or characters.
```{r, echo=FALSE}
str(sample)
```
```{r}
set.seed(1)
sample(1:10, 4)
sample(1:10, 4) ## gives a random sample of 4 elements from the vector
sample(letters, 5) ## also works with character vectors
sample(1:10)  ## if no size is specified, it gives a random permutation.
sample(1:10, replace = TRUE) ## allows an item to be sampled more than once
```

# R Profiler  
Useful tool for very large Data sets, or other work where processing might be taking a very long time. It helps you find out why things are taking so long and suggest strategies for faster solutions. 

## Why is My Code So Slow?  
 * Profiling is a systematic way to examine how much time is spent on different parts of the program. 
 * Useful when trying to optimize your code. 
 * Often code runs fine once, but what if you have to put it in a loop for 1000 iterations? Is it still fast enough? 
 * Profiling is better than guessing. 
 
**On Optimizin your code**  
 * Optimization is not the first priority when writing code. It is more important to focus on readability and making sure it works. 
  -- It's often difficult to understand where exactly your program is spending most of its time, and this cannot be done without performance analysis or profiling.  
> We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. 
> --Donald Knuth

**General Principles**  
 * Design first, then optimize 
 * Remember premature optimization is the root of all evil 
 * Measure (collect data), don't guess. 
 * If you're going to be a scientist, you need to apply the same principles here. 

## Using `system.time()` 
 * Takes an arbitrary R expression as input (can be wrapped in curly braces) and returns the amount of time taken to evaluate the expression. 
 * Computes the time (in seconds) needed to execute an expression. 
  -- If there's an error, it gives the time until the error occured. 
 * Returns an object of class `proc_time` 
  -- **user time**: time charged to the CPU for this expression 
  -- **elapsed time**: "wall clock" time. 
  -- (usually both times are similar, but may differ if the computer has multiple CPUs and the program can use them, if the CPU spends time waiting for other things to occur, or in other more complex scenarios) 
```{r}
## Example Elapsed time > user time
system.time(readLines("http://www.jhsph.edu"))

## Elapsed time < user time
hilbert <- function(n) {
  i <- 1:n
  1 / outer(i - 1, i, "+")
}
x <- hilbert(1000)
system.time(svd(x))  
 ## the svd function takes advantage of multiple cores in some computers.

system.time( {
  n <- 1000
  r <- numeric(n)
  for (i in 1:n) {
    x <- rnorm(n)
    r[i] <- mean(x)
  }
  print(summary(r))
})  ## example of system.time using curly braces. 
```
 * `system.time()` allows you to test cartain functions or code blocks to see if they are taking excessive amounts of time. 
 * this assumes you already know where the problem is and can call `system.time()` on it. 

## Using `Rprof()`  
 * The `Rprof()` functions starts the profiler in R. 
  -- R must be compiled with profiler support, but this is usually the case. 
 * the `summaryRprof()` function summarizes the output from `Rprof()`. The raw output is unreadable. 
 * **DO NOT** use `system.time()` and `Rprof()` together. 

 * `Rprof()` keeps track of the function call stack at regularly sampled intervals and tabulates how much time is spent in each function. 
 * default sampling interval is 0.02 seconds. 
 * Note: if your code runs very quickly, the profiler is not helpful, but then you probably don't need it anyway. 

### Using `summaryRprof()`  
 * This function tabulates the R profiler and calculates how much time is spent in which function. 
 * There are two methods for normalizing the data. 
 * `by.total` divides the time spent in each function by the total run time. 
 * `by.self` does the same but first it subtracts out time spent in functions above the call stack. 

